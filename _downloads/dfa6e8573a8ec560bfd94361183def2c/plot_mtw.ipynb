{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\nMulti-subject joint source localization with MTW\n================================================\n\nThe aim of this tutorial is to show how to leverage functional similarity\nacross subjects to improve source localization with a spatial prior using\nOptimal transport (Janati et al, 2019). Unlike multi-task Lasso which assumes\nthat the exact same sources are active for all subjects, MTW promotes a soft\nspatial proximity prior of sources across subjects. This example illustrates\nthis on the the high frequency SEF MEG dataset of (Nurminen et al., 2017)\nwhich provides MEG and MRI data for two subjects.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Author: Hicham Janati (hicham.janati@inria.fr)\n#\n# License: BSD (3-clause)\n\nimport os\nimport os.path as op\n\nfrom matplotlib import pyplot as plt\n\nimport mne\nfrom mne.parallel import parallel_func\nfrom mne.datasets import hf_sef\n\nfrom groupmne import compute_group_inverse, prepare_fwds, compute_fwd"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Download and process MEG data\n-----------------------------\n\nFor this example, we use the HF somatosensory dataset [2].\nWe need the raw data to estimate the noise covariance\nsince only average MEG data (and MRI) are provided in \"evoked\".\nThe data will be downloaded in the same location\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "_ = hf_sef.data_path(\"raw\")\ndata_path = hf_sef.data_path(\"evoked\")\nmeg_path = data_path + \"/MEG/\"\n\ndata_path = op.expanduser(data_path)\nsubjects_dir = data_path + \"/subjects/\"\nos.environ['SUBJECTS_DIR'] = subjects_dir\n\nraw_name_s = [meg_path + s for s in [\"subject_a/sef_right_raw.fif\",\n              \"subject_b/hf_sef_15min_raw.fif\"]]\n\n\ndef process_meg(raw_name):\n    \"\"\"Extract epochs from a raw fif file.\n\n    Parameters\n    ----------\n    raw_name: str\n        path to the raw fif file.\n\n    Returns\n    -------\n    epochs: Epochs instance\n\n    \"\"\"\n    raw = mne.io.read_raw_fif(raw_name)\n    events = mne.find_events(raw)\n\n    event_id = dict(hf=1)  # event trigger and conditions\n    tmin = -0.05  # start of each epoch (50ms before the trigger)\n    tmax = 0.3  # end of each epoch (300ms after the trigger)\n    baseline = (None, 0)  # means from the first instant to t = 0\n    epochs = mne.Epochs(raw, events, event_id, tmin, tmax, proj=True,\n                        baseline=baseline)\n    return epochs\n\n\nepochs_s = [process_meg(raw_name) for raw_name in raw_name_s]\nevokeds = [ep.average() for ep in epochs_s]\n\n# compute noise covariance (takes a few minutes)\nnoise_covs = []\nfor subj, ep in zip([\"a\", \"b\"], epochs_s):\n    cov_fname = meg_path + f\"subject_{subj}/sef-cov.fif\"\n    cov = mne.compute_covariance(ep[:100], tmin=None, tmax=0.)\n    noise_covs.append(cov)\n\n\nf, axes = plt.subplots(1, 2, sharey=True)\nfor ax, ev, nc, ll in zip(axes.ravel(), evokeds, noise_covs, [\"a\", \"b\"]):\n    picks = mne.pick_types(ev.info, meg=\"grad\")\n    ev.plot(picks=picks, axes=ax, noise_cov=nc, show=False)\n    ax.set_title(\"Subject %s\" % ll, fontsize=15)\nplt.show()\n\ndel epochs_s"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Source and forward modeling\n---------------------------\nTo guarantee an alignment across subjects, we start by\ncomputing the source space of `fsaverage`\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "resolution = 4\nspacing = \"ico%d\" % resolution\n\nfsaverage_fname = op.join(subjects_dir, \"fsaverage\")\nif not op.exists(fsaverage_fname):\n    mne.datasets.fetch_fsaverage(subjects_dir)\n\nsrc_ref = mne.setup_source_space(subject=\"fsaverage\",\n                                 spacing=spacing,\n                                 subjects_dir=subjects_dir,\n                                 add_dist=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Compute forward models with a reference source space\n----------------------------------------------------\nthe function `compute_fwd` morphs the source space src_ref to the\nsurface of each subject by mapping the sulci and gyri patterns\nand computes their forward operators. Next we prepare the forward operators\nto be aligned across subjects\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "subjects = [\"subject_a\", \"subject_b\"]\ntrans_fname_s = [meg_path + \"%s/sef-trans.fif\" % s for s in subjects]\nbem_fname_s = [subjects_dir + \"%s/bem/%s-5120-bem-sol.fif\" % (s, s)\n               for s in subjects]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Before computing the forward operators, we make sure the coordinate\ntransformation of the trans file provides a reasonable alignement between the\ndifferent coordinate systems MEG <-> HEAD\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "for raw_fname, trans, subject in zip(raw_name_s, trans_fname_s, subjects):\n    raw = raw = mne.io.read_raw_fif(raw_fname)\n    fig = mne.viz.plot_alignment(raw.info, trans=trans, subject=subject,\n                                 subjects_dir=subjects_dir,\n                                 surfaces='head-dense',\n                                 show_axes=True, dig=True, eeg=[],\n                                 meg='sensors',\n                                 coord_frame='meg')\n\nn_jobs = 1\nparallel, run_func, _ = parallel_func(compute_fwd, n_jobs=n_jobs)\n\n\nfwds_ = parallel(run_func(s, src_ref, info, trans, bem,  mindist=3)\n                 for s, info, trans, bem in zip(subjects, raw_name_s,\n                                                trans_fname_s, bem_fname_s))\n\nfwds = prepare_fwds(fwds_, src_ref, copy=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Solve the inverse problems with Multi-task Wasserstein (MTW)\n------------------------------------------------------------\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# The Multi-task Wasserstein promotes sparse source estimates are spatially\n# close across subjects for each time point. `alpha` is a hyperparameter that\n# controls the spatial prior; `beta` the sparsity prior. `alpha` must be\n# non-negative, `beta` must be set as a positive number between 0\n# and 1. With `beta` = 1, all the sources are 0.\n\n# We restric the time points to 20ms in order to reconstruct the sources of\n# the N20 response.\n\nevokeds = [ev.crop(0.02, 0.02) for ev in evokeds]\nstcs_mtw = compute_group_inverse(fwds, evokeds, noise_covs,\n                                 method='remtw',\n                                 spatiotemporal=False,\n                                 alpha=1.,\n                                 beta=0.05,\n                                 n_jobs=2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's visualize the N20 response. The stimulus was applied on the right\nhand, thus we only show the left hemisphere. The activation is exactly in\nthe primary somatosensory cortex. We highlight the borders of the post\ncentral gyrus.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "t = 0.02\nplot_kwargs = dict(\n    hemi='lh', subjects_dir=subjects_dir, views=\"lateral\",\n    initial_time=t, time_unit='s', size=(800, 800),\n    smoothing_steps=5, cortex=(\"gray\", -1, 6, True))\n\nt_idx = stcs_mtw[0].time_as_index(t)\n\nfor stc, subject in zip(stcs_mtw, subjects):\n    g_post_central = mne.read_labels_from_annot(subject, \"aparc.a2009s\",\n                                                subjects_dir=subjects_dir,\n                                                regexp=\"G_postcentral-lh\")[0]\n    n_sources = [stc.vertices[0].size, stc.vertices[1].size]\n    m = abs(stc.data[:n_sources[0], t_idx]).max()\n    plot_kwargs[\"clim\"] = dict(kind='value', pos_lims=[0., 0.2 * m, m])\n    brain = stc.plot(**plot_kwargs)\n    brain.add_text(0.1, 0.9, \"multi-subject-mtw (%s)\" % subject,\n                   \"title\")\n    brain.add_label(g_post_central, borders=True, color=\"green\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Comparison with Single subject Lasso\n-----------------------------------------------\nTo evaluate the effect of the MTW prior, we compute the independent Lasso\nsolution\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "stcs = compute_group_inverse(fwds, evokeds, noise_covs,\n                             method='relasso',\n                             spatiotemporal=False,\n                             alpha=0.05)\n\nfor stc, subject in zip(stcs, subjects):\n    stc.subject = subject\n    g_post_central = mne.read_labels_from_annot(subject, \"aparc.a2009s\",\n                                                subjects_dir=subjects_dir,\n                                                regexp=\"G_postcentral-lh\")[0]\n    n_sources = [stc.vertices[0].size, stc.vertices[1].size]\n    m = abs(stc.data[:n_sources[0], t_idx]).max()\n    plot_kwargs[\"clim\"] = dict(kind='value', pos_lims=[0., 0.2 * m, m])\n    brain = stc.plot(**plot_kwargs)\n    brain.add_text(0.1, 0.9, \"single-subject-lasso (%s)\" % subject,\n                   \"title\")\n    brain.add_label(g_post_central, borders=True, color=\"green\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "References\n----------\n[1] Hicham Janati, Thomas Bazeille, Bertrand Thirion, Marco Cuturi,\nAlexandre Gramfort. Group level MEG/EEG source imaging via optimal transport:\nminimum Wasserstein estimates (IPMI 2019)\n\n\n[2] Jussi Nurminen, Hilla Paananen, & Jyrki M\u00e4kel\u00e4. (2017). High frequency\nsomatosensory MEG: evoked responses, FreeSurfer reconstruction [Data set].\nZenodo. http://doi.org/10.5281/zenodo.889235\n\n\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}